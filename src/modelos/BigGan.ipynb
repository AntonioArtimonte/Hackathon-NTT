{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração das transformações de imagem\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Carregando o dataset (substitua 'path_to_data' pelo caminho do seu dataset)\n",
    "dataset = datasets.ImageFolder(root='/home/rodrigo/Repos/Hackathon-NTT/src/modelos/dataset/images/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Linear(in_features=49152, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Garantir que a entrada seja achatada corretamente\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "# Definindo parâmetros do modelo\n",
    "z_dim = 100\n",
    "img_dim = 128 * 128 * 3  # Para imagens de 128x128 com 3 canais de cor\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "num_epochs = 220\n",
    "\n",
    "# Criando instâncias dos modelos\n",
    "gen = Generator(z_dim, img_dim)\n",
    "disc = Discriminator(img_dim)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "# Configuração do otimizador e da função de perda\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Movendo modelos para GPU se disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen.to(device)\n",
    "disc.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/220]  Loss D: 0.0018, Loss G: 7.7455\n",
      "Epoch [1/220]  Loss D: 0.0509, Loss G: 10.7221\n",
      "Epoch [2/220]  Loss D: 0.0102, Loss G: 6.0236\n",
      "Epoch [3/220]  Loss D: 0.0492, Loss G: 6.4831\n",
      "Epoch [4/220]  Loss D: 0.0656, Loss G: 3.9147\n",
      "Epoch [5/220]  Loss D: 0.2319, Loss G: 3.2086\n",
      "Epoch [6/220]  Loss D: 0.0659, Loss G: 6.4550\n",
      "Epoch [7/220]  Loss D: 25.0000, Loss G: 100.0000\n",
      "Epoch [8/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [9/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [10/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [11/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [12/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [13/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [14/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [15/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [16/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [17/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [18/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [19/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [20/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [21/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [22/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [23/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [24/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [25/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [26/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [27/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [28/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [29/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [30/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [31/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [32/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [33/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [34/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [35/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [36/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [37/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [38/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [39/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [40/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [41/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [42/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [43/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [44/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [45/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [46/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [47/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [48/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [49/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [50/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [51/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [52/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [53/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [54/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [55/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [56/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [57/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [58/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [59/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [60/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [61/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [62/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [63/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [64/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [65/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [66/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [67/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [68/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [69/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [70/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [71/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [72/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [73/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [74/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [75/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [76/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [77/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [78/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [79/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [80/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [81/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [82/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [83/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [84/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [85/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [86/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [87/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [88/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [89/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [90/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [91/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [92/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [93/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [94/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [95/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [96/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [97/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [98/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [99/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [100/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [101/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [102/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [103/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [104/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [105/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [106/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [107/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [108/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [109/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [110/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [111/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [112/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [113/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [114/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [115/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [116/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [117/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [118/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [119/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [120/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [121/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [122/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [123/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [124/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [125/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [126/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [127/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [128/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [129/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [130/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [131/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [132/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [133/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [134/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [135/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [136/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [137/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [138/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [139/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [140/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [141/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [142/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [143/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [144/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [145/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [146/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [147/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [148/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [149/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [150/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [151/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [152/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [153/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [154/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [155/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [156/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [157/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [158/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [159/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [160/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [161/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [162/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [163/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [164/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [165/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [166/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [167/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [168/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [169/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [170/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [171/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [172/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [173/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [174/220]  Loss D: 50.0000, Loss G: 0.0000\n",
      "Epoch [175/220]  Loss D: 50.0000, Loss G: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m     gen\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     34\u001b[0m     loss_gen\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mopt_gen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]  Loss D: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_disc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss G: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_gen\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repos/Hackathon-NTT/src/venv/lib/python3.12/site-packages/torch/optim/adam.py:433\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    431\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[0;32m--> 433\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Diretório onde as imagens serão salvas\n",
    "output_dir = '/home/rodrigo/Repos/Hackathon-NTT/src/modelos/images/'\n",
    "\n",
    "# Verifica se o diretório existe, se não existir, cria o diretório\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.view(-1, img_dim).to(device)\n",
    "        \n",
    "        # Gerar imagens falsas usando o gerador\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # Treinando o discriminador\n",
    "        disc_real = disc(real).view(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Treinando o gerador\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}]  Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise).reshape(-1, 3, 128, 128)\n",
    "            img_grid = torchvision.utils.make_grid(fake, normalize=True)\n",
    "            torchvision.utils.save_image(img_grid, os.path.join(output_dir, f\"epoch_{epoch}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(64, z_dim).to(device)\n",
    "    fake_images = gen(noise).reshape(-1, 3, 128, 128)\n",
    "    torchvision.utils.save_image(fake_images, \"generated_images.png\", normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
