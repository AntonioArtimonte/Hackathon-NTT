{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuração das transformações de imagem\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Carregando o dataset (substitua 'path_to_data' pelo caminho do seu dataset)\n",
    "dataset = datasets.ImageFolder(root='/home/rodrigo/Repos/Hackathon-NTT/src/modelos/dataset/images/', transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (disc): Sequential(\n",
       "    (0): Linear(in_features=49152, out_features=1024, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (6): Linear(in_features=256, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gen(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Linear(img_dim, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Garantir que a entrada seja achatada corretamente\n",
    "        return self.disc(x)\n",
    "\n",
    "\n",
    "def initialize_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d, nn.BatchNorm2d)):\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "\n",
    "# Definindo parâmetros do modelo\n",
    "z_dim = 100\n",
    "img_dim = 128 * 128 * 3  # Para imagens de 128x128 com 3 canais de cor\n",
    "lr = 0.0002\n",
    "batch_size = 64\n",
    "num_epochs = 220\n",
    "\n",
    "# Criando instâncias dos modelos\n",
    "gen = Generator(z_dim, img_dim)\n",
    "disc = Discriminator(img_dim)\n",
    "initialize_weights(gen)\n",
    "initialize_weights(disc)\n",
    "\n",
    "# Configuração do otimizador e da função de perda\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Movendo modelos para GPU se disponível\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gen.to(device)\n",
    "disc.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Diretório onde as imagens serão salvas\n",
    "output_dir = '/home/rodrigo/Repos/Hackathon-NTT/src/modelos/images/'\n",
    "\n",
    "# Verifica se o diretório existe, se não existir, cria o diretório\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "fixed_noise = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(dataloader):\n",
    "        real = real.view(-1, img_dim).to(device)\n",
    "        \n",
    "        # Gerar imagens falsas usando o gerador\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "\n",
    "        # Treinando o discriminador\n",
    "        disc_real = disc(real).view(-1)\n",
    "        loss_disc_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake.detach()).view(-1)\n",
    "        loss_disc_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        loss_disc = (loss_disc_real + loss_disc_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        loss_disc.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Treinando o gerador\n",
    "        output = disc(fake).view(-1)\n",
    "        loss_gen = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/{num_epochs}]  Loss D: {loss_disc:.4f}, Loss G: {loss_gen:.4f}\")\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            fake = gen(fixed_noise).reshape(-1, 3, 128, 128)\n",
    "            img_grid = torchvision.utils.make_grid(fake, normalize=True)\n",
    "            torchvision.utils.save_image(img_grid, os.path.join(output_dir, f\"epoch_{epoch}.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    noise = torch.randn(64, z_dim).to(device)\n",
    "    fake_images = gen(noise).reshape(-1, 3, 128, 128)\n",
    "    torchvision.utils.save_image(fake_images, \"generated_images.png\", normalize=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
